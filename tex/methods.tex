\section{Methodology (1 page)}
\label{sec:methods}
This paper aims to study the evalution of browser API usage in phishing pages and leverage execution traces of these pages to identify which two share an underlying kit. To accomplish this, we require browser API execution trances from phishing pages over a long period of time and a subset of pages where we know the underlying phishing kit. In the following section, we describe the experimental setup for gathering this data, the steps we took to aggregate and enrich the execution traces, how we identified anomalies and trends, and finally, the steps we took for clustering the data and evaluating them as an analog for phishing kits. 

\subsection{Data Gathering}

\textbf{URL feeds}: We gathered phishing pages from a diverse set of phishing feeds, monitoring OpenPhish\cite{openphish}, PhishTank\cite{phishtank}, URLScan\cite{urlscan}, SMS Gateways\cite{nahapetyan2024sms}, PhishDB\cite{phishingDB}, and APWG\cite{apwg}, based on the availability of the feed and the level access we had at the time. Every hour, we checked these feeds for new urls (limited to the last 48 hours) and submitted them into two different crawlers: VisibleV8 and KitPhished.

\noindent\textbf{VisibleV8}: To get execution traces for every script loaded when visiting the page, we used an automated chromium-based crawler with VisibleV8 patches applied. The browser is being automated to visit the page and take screenshots with puppeteer\cite{pptr}, an NPM package by Google to help in UI/UX testing and browser automation. The patched chromium crawler uses puppeteer-stealth, a set of configurations to help mask the headless chrome and puppeteer itself from detection tools\cite{puppeteerstealth}. We initiated the crawls from a university network designated for research purposes and use Catapult\cite{catapult}, a man-in-the-middle proxy to capture the entire HTTP archive for replayability. The crawler stays on the page for 45 seconds, before taking a screenshot, in order to allow scripts to load and start executing, this is consistent with prior work\todocite{Jordan and OpenWPM}.

\noindent\textbf{KitPhisher}: While not guaranteed, some malicious actors leave the zip files of the kits used in a discoverable folder on the same server that hosts the website (for example, the Apache document root). KitPhisher\cite{kitphishr} is a go-based URL fuzzer that attempts to identify any left-over zip files on the server. Prior work\todocite{DynaPhish, Oest's paper} establishes it as an excellent way to collect and analyze phishing kits. If it is successful, it will download the zip file and make a note of the domain from which kitphishr acquired it.


\input{figures/infra}
\subsection{Data enrichment}
\subsubsection{Enriching browser API executions}
VisibleV8 comes with a default set of log-postprocessors. These programs take the raw lags generated by the patched Chromium browser and convert it into an organized database, identifying duplicate scripts via sha3 hash, clearly marking the origin of each script that loaded and isolating which javascript API calls are browser API calls via the WebIDL file\footnote{\url{https://developer.mozilla.org/en-US/docs/Glossary/WebIDL}} generated during the while building the patched chromium. For our analysis, we use a tuple of the original page's URL, the script's URL, and a set (unordered) of APIs executed by this script.

To cut through the noise of cloaked pages and include third-party scripts like Google Analytics, known to be present in phishing pages\cite{phishingvLegit}, we isolate API sets executed by first-party scripts (from now on called first-party API sets). To do this, we establish the root domain as the domain submitted to the feeds and the origin as the domain from which the script is loaded. We consider a script first-party only if loaded from the domain we acquired from our feeds (root domain). 

Even focusing on APIs that WebIDL marks, the total number of browser APIs exceeds 15,000. We average Mozila Developer's network ~150 WebAPIs categories when aggregating all the APIs used. However, we also look at prior work by Su\etal{} and Zhang\etal{} for categories of Browser APIs for fingerprinting and general cloaking, respectively. We add onto Crawlphish's table of cloaking categories a new category, Advance fingerprinting, which includes all fingerprinting APIs by the Su\etal{}. We use MDN's documentation to identify a list of 20 browser APIs that trigger a permission pop-up or validate permission. We should note that while \textit{Permissions.query} is the only way to verify permissions; different WebAPIs like USB, clipboard, Geolocation, and Notification have their different APIs for requesting the pop-up

\subsubsection{Cleaning up KitPhisher output}
We crawl the urls with KitPhishr to establish a ground truth dataset with urls originating from the same kit. For \numberencryptedKits{} zip files extracted via kitphishr that have password-based encryption enabled, we use the SHA256 hash of the zip files to which domains yielded the same kit. For the remaining \numberKits{}, we further de-duplicate them into Kit-Families by looking at them as a set of SHA256 of source files\footnote{Sourcefiles identified via libmagic}; if the Jecard-Index-based similarity of these sets is equal or greater than 95\% we consider the two kits to be from the same family, and thus group all domains from both kits into the same group.

\input{figures/ji}


\input{figures/behavior_categories}
\subsection{Identifying trends }
For anomaly detection, we use rapture\todocite{ruptures} to detect changepoints in the time series of API calls. We use the L1 cost function with a linearly penalized segmentation algorithm to find segments based on the mean deviation.
To filter out noise in trends from the miss-balance of pages we get from different feeds, we ignore any API trends that strongly correlate with the number of pages we get from all feeds.
To clear up the results from rapture, we look at the change in the mean between segments. Any chance being less than XXXX, we ignore and merge with the prior segment. 
VisibleV8 will de-duplicate the same script loaded by multiple pages via the sha3 hash of the script. To establish if scripts have non-deterministic behavior, we pull the set of APIs that are executed by the script and compare the set of APIs executed by the same script on different pages. We use the Jaccard index to establish the similarity between the sets of APIs.

\subsection{Identifying kits}

The core hypothesis of this work is that similarity in browser API execution means that the pages originate from the same phishing kit. To establish this similarity, we use the Jaccard index on the set of APIs that first-party scripts execute. 
\DraftToDo{Well\ldots{} what about the whole merging clusters bit?}
We use HDBScan, with a minimum cluster size of 10, to cluster the pages based on the Jaccard index. We then use the ground truth labels from KitPhisher to evaluate the clustering. When ground truth is available, we use Fowlkes-Mallows Index (geometric mean between precision and recall)\cite{fowlkes1983method}, and V-measure to evaluate the clustering.

V-measure is a harmonic mean between completeness (all members in a cluster are from the right class) and homogeneity (all members in a cluster are from the same class). V-measure allows tuning a ratio $\beta$ that prioritizes the score towards one vs the other. More importantly, looking at completeness and homogeneity scores lets you see how your clustering approach is getting things wrong\cite{Rosenberg2007VMeasureAC}.
We use sklearn's measure module to calculate all cluster evaluation metrics.\cite{scikit-learn}.

We use the silhouette score to evaluate the clustering when we do not have ground truth.
\DraftToDo{Go into detail why and mention that while SC is bias against DBSCAN/HDBSCAN, we still get good enough results where we are fine.}